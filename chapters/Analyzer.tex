The semantic analyzer is run after the AST has been generated and therefore the program is all in
the same data structure. The job of the semantic analyzer is not to transform the AST but to analyze it.
There is the possibility for optimizations to be performed during the analysis to improve the AST.
This includes for instance loop unrolling, constant folding or dead code elimination. However, those things
are not part of this thesis and therefore those optimizations have been mentioned in \autoref{sec:forthcoming}.
However, this thesis deals with other types of optimizations. Specifically, bytecode optimization is performed to some extent.

In short, the job of the analyzer is to perform the following things:

\begin{itemize}
    \item Create the symbol table for each scope and block found. This includes all module scopes and each block scope found.
    \item Get all the type information from the expressions.
    \item Perform the semantic checks on all the statements and expressions found in the AST. All the requirements for those nodes
        are explained in \autoref{sec:statements} and \autoref{sec:expressions} respectively.
    \item Add specific node information. This information has been mentioned individually on each tree node on \autoref{sec:tree_nodes}.
\end{itemize}

\section{Technique}

Before any analysis begins, a full module scope analysis needs to be performed. This is done to ensure that when functions are analyzed
(and so do their statements) the module scope is already valid and contains the information needed to have a correct statement analysis. For instance,
if a function has a statement that makes a call to another function on the module, that callee function must be known, so its signature needs to be
analyzed first.

To solve this, a first analysis is performed only on the top level declarations (module scope) found in the module.
If one of the top-level declarations is a use declaration, then that module is first analyzed completely before the current analysis can continue.
The top-level analysis just gets information about the top-level declarations and does not perform further analysis.
That means that it just gets the information of the functions, classes and so on without analyzing the function bodies.
Top level classes are also analyzed only on the top level of their bodies. Once all this phase is complete, the code analysis begins in an arbitrary order.
This can be done as the top level is already analyzed and therefore all the symbol table for the module block is already built and the types are known.

Once the code analysis begins the function bodies are analyzed and so do classes methods. The analysis run by recursively walking the AST and further performing
all the checks mentioned in \autoref{sec:statements} and on \autoref{sec:expressions} depending on the type of node being analyzed.
This analysis is also recursive.

\begin{figure}[H]
	\centering
	\begin{subtable}{0.45\textwidth}
        \texttt{fun main(argv: [string]) \{\\\tab// ...\\\}}
		\caption{Program}
	\end{subtable}
	\begin{subtable}{0.45\textwidth}
		\centering
        \texttt{
            TOKEN\_FUN TOKEN\_IDENTIFIER TOKEN\_LEFT\_PAREN TOKEN\_IDENTIFIER TOKEN\_COLON TOKEN\_LEFT\_SQUARE TOKEN\_IDENTIFIER
            TOKEN\_RIGHT\_SQUARE TOKEN\_RIGHT\_PAREN TOKEN\_LEFT\_BRACE TOKEN\_NEW\_LINE
            TOKEN\_RIGHT\_BRACE TOKEN\_NEW\_LINE
            TOKEN\_EOF
        }
		\caption{List of tokens}
	\end{subtable}
    \begin{subfigure}{0.45\textwidth}
		\centering
        \begin{tikzpicture}[node distance=1.75cm]
            % Nodes
            \node[state] (0) {\texttt{P(1)}};
            \node[state, below of=0] (1) {\texttt{F1}};
            \node[state, below left of=1] (3) {\texttt{P2}};
            \node[state, left of=3] (2) {\texttt{P1}};
            \node[state, below right of=1] (4) {\texttt{P3}};
            \node[state, right of=4] (5) {\texttt{P4}};
            \node[state, below of=5] (6) {\texttt{...}};
            % Legend
            \node[text width=4.5cm, align=left, right = 0.5cm of 0.east] (l) {

                { \footnotesize \noindent
                    \texttt{F1: function}\\
                    \texttt{P1: name:\\\quad main}\\
                    \texttt{P2: parameters\\\quad argv: [string]}\\
                    \texttt{P3: return\_type\\\quad no\_value}\\
                    \texttt{P4: body}
                }
            };
            % Lines
            \draw (0) -- (1);
            \draw (1) -- (2);
            \draw (1) -- (3);
            \draw (1) -- (4);
            \draw (1) -- (5);
            \draw (5) -- (6);
        \end{tikzpicture}
		\caption{Abstract Syntax Tree}
	\end{subfigure}
    \begin{subfigure}{0.45\textwidth}
		\centering
        \begin{tabular}{ l l l }
            \textbf{Variable} & \textbf{Type} \\
            \texttt{main} & \texttt{([string])} \\
		\end{tabular}
		\caption{Module scope symbol table}
	\end{subfigure}
	\caption{Example program top-level analysis}
    \label{fig:ast_example}
\end{figure}

Among other mentioned checks that are specific to certain nodes, some of the checks the analyzer performs are:

\begin{itemize}
    \item Declared variables.
    \item Function return value match.
    \item Functions without return type usage.
    \item Argument type match.
    \item Assignment type match.
    \item List / String / Dictionary index type.
    \item Variable lifetime (\texttt{last\_use}).
    \item Use only exported declarations.
    \item Check for iterator (must be list / dict).
    \item Type matching.
    \item \texttt{main([string])} required on the main module.
\end{itemize}

\section{Type Inference}

Type inference is done in Nuua by the \texttt{Type} class seen on \autoref{ls:type_class}. However, it is used in this layer to get
the expression types of the program. Type inference is ability to get the type of the expressions at compile time. Type inference is
a step needed to perform type checks on the AST. Most nodes require a type check at some point and therefore, type inference can be used
to get the type of the expressions on such nodes. The \texttt{Type} class has a constructor that accepts an expression and a list of blocks.
This constructor can determine the expression type and if the expression contains variables, their type is obtained from the block list,
starting from the last block going back till the first block of the list. Although errors are checked, the expression should always be analyzed prior
to any type inference to avoid issues.

\section{Module class}

The module class is used to analyze a module. It automatically creates a new instance of it when it needs to analyze
the AST of a use declaration.

\autoref{ls:module_class} shows the implementation of the module class used by the analyzer\\

\begin{code}
\begin{minted}{cpp}
class Module
{
    // Stores the file name of that module.
    std::shared_ptr<const std::string> file;
    // Stores the code of that module.
    std::shared_ptr<std::vector<std::shared_ptr<Statement>>> code;
    // Stores the blocks used while analyzing the module.
    std::vector<std::shared_ptr<Block>> blocks;
    // Return variable if needs to be checked. Only 1 can exist since
    // it can only analyze 1 function at a time.
    std::shared_ptr<Type> return_type;
    // Analyzes the TLDs of the current module.
    void analyze_tld();
    // Analyzes the given top level declaration.
    void analyze_tld(const std::shared_ptr<Statement> &tld, const bool set_exported = false);
    // Analyzes the class top level declarations.
    // void analyze_class_tld(const std::shared_ptr<Class> &c);
    void analyze_class_tld(const std::shared_ptr<Statement> &tld, const std::shared_ptr<Block> &block);
    // Analyzes the code.
    void analyze_code();
    // Analyzes the statement.
    void analyze_code(const std::shared_ptr<Statement> &rule, bool no_declare = false);
    // Analyzes the expression.
    void analyze_code(const std::shared_ptr<Expression> &rule, const bool allowed_noreturn_call = false);
    // Analyzes the block.
    std::shared_ptr<Block> analyze_code(
        const std::vector<std::shared_ptr<Statement>> &code,
        const std::vector<std::shared_ptr<Declaration>> &initializers = std::vector<std::shared_ptr<Declaration>>(),
        const std::shared_ptr<Node> &initializer_node = std::shared_ptr<Node>()
    );
    // Declares a variable to the most top level block.
    void declare(const std::shared_ptr<Declaration> &dec, const std::shared_ptr<Node> &node = std::shared_ptr<Node>());
    // Check if the given module have all the classes defined.
    bool check_classes(const std::vector<std::string> &classes, const std::shared_ptr<Node> &fail_at);
    public:
        // Stores the main block of that module.
        std::shared_ptr<Block> main_block = std::make_shared<Block>();
        // Main module constructor
        Module(std::shared_ptr<const std::string> &file)
            : file(file) {}
        // Analyzes the module and adds it's entry to the modules symbol table.
        std::shared_ptr<Block> analyze(std::shared_ptr<std::vector<std::shared_ptr<Statement>>> &code, const bool require_main = false);
};
\end{minted}
\caption{Module class}
\label{ls:module_class}
\end{code}

\section{Module In-memory Cache}

Since a module might be imported more than once as shown in \autoref{fig:module_mem_cache} the analyzer
have an in-memory cache to know when a module has been analyzed to avoid redundant analyses.
Once a module has been analyzed it is added into a list of analyzed modules and when a new module is required to be
analyzed is first checked if it has been. If the module has already been analyzed it returns its module scope symbol table and otherwise, it gets analyzed.
